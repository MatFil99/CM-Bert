import tests
import tests.multimodal_tokenizer_test

## cmu_dataset tests ##
# tests.cmu_dataset_test.download_datasets_t1()

# tests.cmu_dataset_test.load_data_t1()

# tests.cmu_dataset_test.remove_unmatched_segments_t1() # changed - needs test

# tests.cmu_dataset_test.align_features_t1()

# tests.cmu_dataset_test.align_labels_t1()

# tests.cmu_dataset_test.word_vectors_2_sentences_t1()

# tests.cmu_dataset_test.remove_special_text_tokens_t1()

# tests.cmu_dataset_test.computational_sequences_2_array_t1()
# tests.cmu_dataset_test.computational_sequences_2_array_t2()

# tests.cmu_dataset_test.words_2_sentences_t1()

# tests.cmu_dataset_test.train_test_valid_split_t1()

## multimodal_tokenizer tests ##
# tests.multimodal_tokenizer_test.init_t1()
# tests.multimodal_tokenizer_test.tokenize_t1()